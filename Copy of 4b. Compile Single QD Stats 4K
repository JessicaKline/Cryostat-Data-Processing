{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_MEfvP55tFmE"},"outputs":[],"source":["#### Mount Sharepoint #####\n","\n","!wget https://downloads.rclone.org/v1.61.1/rclone-v1.61.1-linux-amd64.deb\n","!apt install ./rclone-v1.61.1-linux-amd64.deb\n","\n","!rclone config\n","\n","!sudo mkdir /content/sharepoint\n","!nohup rclone --vfs-cache-mode writes mount sharepoint: /content/sharepoint &\n","\n","#### Mount Sharepoint #####"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vJBJ6EQftMYy"},"outputs":[],"source":["#@title imports\n","#### Common Imports #####\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from matplotlib.ticker import MultipleLocator\n","import math\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","import logging\n","from scipy import optimize\n","import seaborn as sns\n","\n","#### Common Imports #####\n","\n","#### RC Params #####\n","\n","plt.rcParams['savefig.dpi'] = 300\n","plt.rcParams['font.size'] = 22\n","plt.rcParams['font.family'] = 'sans-serif'\n","plt.rcParams['font.sans-serif'] = 'Arial'\n","plt.rcParams['xtick.major.pad']='10'\n","plt.rcParams['ytick.major.pad']='4'\n","\n","logging.getLogger('matplotlib.font_manager').disabled = True\n","\n","#### RC Params #####\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"LLI7xFaAtS5J"},"outputs":[],"source":["#@title helper functions\n","\n","#### Common Helper Functions #####\n","\n","def save_fig(filename):\n","  plt.savefig(filename, bbox_inches = 'tight')\n","\n","def read_csv(file_path):\n","  g2 = pd.read_csv(file_path)\n","  g2 = g2.to_numpy()\n","  return g2\n","\n","def save_fig(filename):\n","  plt.savefig(filename, bbox_inches = 'tight')\n","\n","def set_figsize(width_, height_):\n","  ff = plt.gcf()\n","  ff.set_figwidth(width_)\n","  ff.set_figheight(height_)\n","  ff.tight_layout()\n","\n","def tick_settings(x_minor = 1, y_minor = 1):\n","  plt.gca().xaxis.set_minor_locator(MultipleLocator(x_minor))\n","  plt.gca().yaxis.set_minor_locator(MultipleLocator(y_minor))\n","  plt.gca().tick_params(which='minor', bottom=True, top=True, left=True, right=True)\n","  plt.gca().tick_params(bottom=True, top=True, left=True, right=True)\n","  plt.tick_params(axis = 'both', direction = 'in', length = 6, width = 1.5)\n","  plt.gca().tick_params(which='minor', direction = \"in\", length = 4, width = 0.75)\n","\n","  for axis in ['top','bottom','left','right']:\n","    plt.gca().spines[axis].set_linewidth(1.5)\n","\n","def plot_settings(y_lim, x_lim, y_min, x_min, x_label, y_label):\n","  plt.gca().set_ylim(y_lim)\n","  plt.gca().set_xlim(x_lim)\n","  tick_settings(y_minor = y_min, x_minor = x_min)\n","\n","  plt.gca().set_xlabel(x_label, fontweight = 'bold')\n","  plt.gca().set_ylabel(y_label, fontweight = 'bold')\n","\n","def save_csv_report(fits, col_lst ,filename):\n","  fits = pd.DataFrame(fits.T)\n","  fits.columns = col_lst\n","  fits.to_csv(filename)\n","\n","def find_nearest(array, value):\n","    array = np.asarray(array)\n","    idx = (np.abs(array - value)).argmin()\n","    return idx\n","\n","def get_onlyfile(folder):\n","  return [f for f in listdir(folder) if isfile(join(folder, f))]\n","\n","#### Common Helper Functions #####\n","\n","def jacobian_transform(x_w, I_w):\n","  hc = 1239.8\n","\n","  x_E_ev = hc/x_w\n","  x_frequency = 3E8/(x_w*1E-9)\n","  I_E = I_w/(x_E_ev**2)\n","  I_E = I_E/(x_frequency**3)\n","  #I_E = I_E/np.sum(I_E)\n","  #I_E = I_E / np.amax(I_E)\n","\n","  return np.array([x_E_ev, I_E]).T\n","\n","def gaussian(x, amplitude1, mean1, stddev1):\n","    return amplitude1/(stddev1*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean1) /(stddev1))**2)\n","\n","def gaussian_b(x, amplitude1, mean1, stddev1, b):\n","    return amplitude1/(stddev1*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean1) /(stddev1))**2) + b\n","\n","def gaussian2(x, amplitude1, mean1, stddev1, amplitude2, mean2, stddev2):\n","    return amplitude1/(stddev1*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean1) /(stddev1))**2) + amplitude2/(stddev2*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean2) /(stddev2))**2)\n","\n","def gaussian3(x, amplitude1, mean1, stddev1, amplitude2, mean2, stddev2, amplitude3, mean3, stddev3):\n","    return amplitude1/(stddev1*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean1) /(stddev1))**2) + amplitude2/(stddev2*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean2) /(stddev2))**2) + amplitude3/(stddev3*np.sqrt(2*3.14)) * np.exp(-0.5*((x - mean3) /(stddev3))**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrDdSM3d9ggQ"},"outputs":[],"source":["folder_string_lst = ['insert folders here']\n","\n","for folder_string in folder_string_lst:\n","\n","  directory = 'parent directory'+folder_string\n","\n","  t_avg = []\n","  beta = []\n","  g2_lst = []\n","  on = []\n","  off = []\n","  grey = []\n","  bc_type = []\n","  auger_type = []\n","  hc_type = []\n","  num_lst = []\n","  total_counts_lst = []\n","  max_counts = []\n","  last_on_event = []\n","  num_levels = []\n","  decay_rate = []\n","  blinking_events = []\n","\n","  integrated_em_max = []\n","  integrated_FWHM = []\n","  avg_single_shot_em_max = []\n","  avg_single_shot_FWHM = []\n","  t5_SF_em_max = []\n","  t600_SF_em_max = []\n","  t5_SF_FWHM = []\n","  t600_SF_FWHM = []\n","\n","  dell_inf = []\n","  t_c = []\n","\n","\n","  for qd_num in range(1, 200):\n","    qd_num_path = directory + f'QD{qd_num}/'\n","    if os.path.exists(qd_num_path) == True:\n","      apd_loc_path = qd_num_path + 'APD/Analyzed Data/'\n","      spectra_loc_path = qd_num_path + 'Spectra/Analyzed Data/'\n","\n","      ## g2 values\n","      g2_val = open(apd_loc_path+\"g2_val.txt\", \"r\")\n","      g2_val = g2_val.read()\n","\n","      if float(g2_val) < 0.5:\n","        g2_lst.append(float(g2_val))\n","\n","        num_lst.append(qd_num)\n","\n","        ## average lifetime\n","        ## beta value\n","        QD_TRPL_Fit = pd.read_csv(apd_loc_path+\"QD_TRPL_Fit.csv\")\n","        QD_TRPL_Fit = QD_TRPL_Fit.to_numpy()\n","\n","        t_avg.append(QD_TRPL_Fit[0,1])\n","        beta.append(QD_TRPL_Fit[3,1])   ### alpha at 4K\n","\n","\n","        ## count auger vs BC vs HC\n","        a_v_b = read_csv(apd_loc_path+\"FLID_fit_paras.csv\")\n","        t_c.append(a_v_b[0][1])\n","        dell_inf.append(a_v_b[0][5])\n","        if len(a_v_b[0]) == 8:\n","          bc_type.append(a_v_b[0][7])\n","          auger_type.append(1-a_v_b[0][7])\n","          hc_type.append(0)\n","        else:\n","          sum_temp = np.sum(a_v_b[0][7:10])\n","          bc_type.append(a_v_b[0][7]/sum_temp)\n","          auger_type.append(a_v_b[0][8]/sum_temp)\n","          hc_type.append(a_v_b[0][9]/sum_temp)\n","\n","\n","        ## ON vs Grey vs OFF\n","        ## ON defined as max intensity state\n","        ## OFF defined as min intensity state\n","        ## GREY is everything else\n","        state_lst = read_csv(apd_loc_path+\"state_stats.csv\")\n","        max_counts.append(np.nanmax(state_lst[:,1]))\n","\n","        num_levels.append(len(state_lst[:,1]))\n","\n","        max_int = np.argmax(state_lst[:,1])\n","        min_int = np.argmin(state_lst[:,1])\n","\n","        state_lst[:,1][state_lst[:,1] < 500] = 500\n","        frac = (state_lst[:,1] - 500)/(state_lst[max_int, 1] - 500)\n","        off_temp = (1-frac)*state_lst[:,3]\n","        off.append(np.nansum(off_temp))\n","\n","        on_temp = frac*state_lst[:,3]\n","        on.append(np.nansum(on_temp))\n","\n","        grey.append(0)\n","\n","\n","        ##time of last on event\n","        times = read_csv(apd_loc_path+'last_ON_event.csv')\n","        last_on_event.append(np.nanmax(times))\n","\n","        ## total intensity\n","        total_counts_val = open(apd_loc_path+\"total_counts.txt\", \"r\")\n","        total_counts_val = total_counts_val.read()\n","        total_counts_lst.append(float(total_counts_val))\n","\n","        ## emission max and FWHM\n","        int_pl = read_csv(spectra_loc_path+'Time_Average_Params.csv')\n","        integrated_em_max.append(int_pl[1,1])\n","        integrated_FWHM.append(int_pl[2,1])\n","\n","        int_pl = read_csv(spectra_loc_path+'Time_Slice_Data.csv')\n","        avg_single_shot_em_max.append(np.nanmedian(int_pl[:,2]))\n","        avg_single_shot_FWHM.append(np.nanmedian(int_pl[:,3]))\n","\n","        t5_SF_em_max.append(np.nanmedian(int_pl[0:5,2]))\n","        t600_SF_em_max.append(np.nanmedian(int_pl[-5:,2]))\n","        t5_SF_FWHM.append(np.nanmedian(int_pl[0:5,3]))\n","        t600_SF_FWHM.append(np.nanmedian(int_pl[-5:,3]))\n","\n","\n","        #int_pl = read_csv(spectra_loc_path+'Dell_Sq_Params.csv')\n","        ## dell_inf, t_c, sigma\n","        #dell_inf.append(int_pl[0,1])    ### units of meV^2 (plateu value) (long time expected difference in mean sq energy)\n","        #t_c.append(int_pl[1,1])         ### units of s (time to get to plateu)\n","\n","        ### decay rate\n","        decay_txt = open(apd_loc_path+\"decay_fit.txt\", \"r\")\n","        decay_txt = decay_txt.read()\n","        decay_txt = decay_txt.split()\n","        decay_para = [float(x) for x in decay_txt]\n","\n","        decay_rate.append(decay_para[0]*1000)\n","\n","\n","\n","      # else:\n","      #   print(g2_val)\n","\n","\n","  print(directory)\n","  print(len(num_lst))\n","  total_arr = np.array([num_lst,total_counts_lst, t_avg, beta, g2_lst, on, grey, off, bc_type, auger_type, max_counts, last_on_event, num_levels, integrated_em_max,\n","                        integrated_FWHM, avg_single_shot_em_max, avg_single_shot_FWHM, dell_inf,t_c, t5_SF_em_max, t600_SF_em_max, t5_SF_FWHM,  t600_SF_FWHM, decay_rate, hc_type])\n","\n","  arr_labels = ['QD num','total counts',  't avg (ns)', 'beta', 'g2', 'ON', 'GREY', 'OFF', 'bc type', 'auger type', 'max cps', 'time last ON (s)', 'num_levels',\n","                'integrated em max (eV)', 'integrated fwhm (meV)', 'avg single shot em max (eV)', 'avg single shot fwhm (meV)', 'dell inf sq (meV^2)', 't_c (s)', 't5 SF em. max (eV)',\n","                't600 SF em. max (eV)', 't5 SF FWHM (meV)', 't600 SF FWHM (meV)', 'decay rate (cps^2)', 'hc type']\n","\n","  save_csv_report(total_arr, arr_labels, directory +'Compiled_QD_Stats.csv')"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPj1Wg+OifRCaJt06zazhBL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}